# -*- coding: utf-8 -*-
'''
Load graph file. Compute image feature for all the keyframes and save


'''
import torch
from PIL import Image
from ssg2d.models import encoder
from torchvision import transforms
import os,json, argparse
# import open3d as o3d
# import numpy as np
# from pathlib import Path
from tqdm import tqdm
import codeLib
from codeLib.common import normalize_imagenet, create_folder
from ssg2d.utils import util_data
import ssg2d.define as define
import h5py

def Parser(add_help=True):
    parser = argparse.ArgumentParser(description='Process some integers.', formatter_class = argparse.ArgumentDefaultsHelpFormatter,
                                      add_help=add_help)
    parser.add_argument('--config', type=str, default='./configs/default.yaml', help='configuration file name. Relative path under given path (default: config.yml)')
    parser.add_argument('--type', type=str, default='train', choices=['train', 'test', 'validation'], help="allow multiple rel pred outputs per pair",required=False)
    parser.add_argument('--relation', type=str,default='relationships', choices=['relationships_extended', 'relationships'])
    parser.add_argument('--target_scan', type=str, default='', help='path to a txt file that contains a list of scan ids that you want to use.')    
    parser.add_argument('--scan_name', type=str, default='graph.json', 
                        help='what is the name of the output filename of the ply generated by your segmentation method.')
    parser.add_argument('--overwrite', type=int, default=0, help='overwrite existing file.')
    parser.add_argument('--save_batch', type=int, default=0, help='save image feature to a single file.')
    
    # options
    parser.add_argument('--verbose', type=bool, default=False, help='verbal',required=False)
    parser.add_argument('--debug', type=int, default=0, help='debug',required=False)
    return parser

debug = True
debug = False

def process(scan_name, cfg, scan_id, rotate, h5g):
    ''' load graph file '''
    pth_pd = os.path.join(define.DATA_PATH,scan_id,scan_name)
    graph = util_data.load_graph(pth_pd)
    # nodes = graph['nodes']
    keyframes = graph['kfs']
    
    # create_folder(os.path.join(cfg.data.img_feature_path))
    # pth_out = os.path.join(cfg.data.img_feature_path,scan_id+'.pkl')
    # check if file exist
    # if args.save_batch:
    #     if not overwrite and os.path.isfile(pth_out):
    #         return 
    
    '''check if transform is needed'''
    if cfg.data.img_size > 0:
        transform = transforms.Compose([
            transforms.Resize(cfg.data.img_size),
            transforms.ToTensor(),
        ])
    else:
        transform = transforms.Compose([
            transforms.ToTensor(),
        ])

    '''load images'''    
    img_list = list()
    # map2idx = dict()
    # counter=0
    for idx in range(len(keyframes)):
        kf = keyframes[idx]
        img_path = kf['path']
        
        # if not args.save_batch and not overwrite:
        #     pth = os.path.join(cfg.data.img_feature_path,scan_id,str(idx)+'.pkl')
        #     if os.path.isfile(pth):
        #         continue
        
        # keyframes
        if rotate:
            image = Image.open(img_path).rotate(-90,expand=True) # need to rotate. if it's 3RScan
        else:
            image = Image.open(img_path)
        image = transform(image)
        
        # import matplotlib.pyplot as plt
        # plt.imshow(image.permute(1,2,0), cmap="gray")
        # plt.show()
        image = normalize_imagenet(image)
        img_list.append(image)
        # map2idx[counter]=idx
        # counter+=1
        
    if len(img_list) == 0:
        return 
    
    '''compute feature'''
    feature_type = cfg.model.node_encoder.backend
    img_encoder = encoder.image_encoder_dict[feature_type](c_dim=cfg.model.img_feature_dim,normalize=False,use_linear=False)
    img_encoder = img_encoder.eval()
    for param in img_encoder.parameters(): param.requires_grad = False
    img_encoder = img_encoder.to(cfg.DEVICE)
    #compute
    images = torch.stack(img_list).to(cfg.DEVICE)
    with torch.no_grad():
        img_features = torch.cat([ img_encoder(p_split).to('cpu')  for p_split in torch.split(images,int(16), dim=0) ], dim=0)
    # rotate back
    if rotate:
        img_features = torch.rot90(img_features,1,[2,3]) # rotate back

    '''save'''
    if feature_type in h5g: del h5g[feature_type]
    h5g.create_dataset(feature_type,data=img_features.numpy())
    return 
        
    # if args.save_batch:
    #     save_obj(img_features, pth_out)
    #     loaded = load_obj(pth_out)
    #     if (img_features != loaded).any(): print('wrong')
    # else:
    #     create_folder(os.path.join(cfg.data.img_feature_path,scan_id))
    #     for map_idx in range(img_features.shape[0]):
    #         kf_idx = map2idx[map_idx]
    #         x = img_features[map_idx].clone()
    #         pth_out = os.path.join(cfg.data.img_feature_path,scan_id,str(kf_idx)+'.pkl')
    #         save_obj(x, pth_out)
    #         loaded = load_obj(pth_out)
    #         if (x != loaded).any(): print('wrong')

if __name__ == '__main__':
    args = Parser().parse_args()
    '''load config'''
    cfg = codeLib.Config(args.config)    
    # cfg.model.node_encoder.backend = 'resnet18'
    # cfg.model.node_encoder.backend = 'vgg16'
    if torch.cuda.is_available() and len(cfg.GPU) > 0:
        cfg.DEVICE = torch.device("cuda")
    else:
        cfg.DEVICE = torch.device("cpu")
    
    print('use backend',cfg.model.node_encoder.backend)
    
    debug |= args.debug
    args.verbose |= args.debug
    codeLib.utils.util.set_random_seed(cfg.SEED)
    
    ''' Read Scan and their type=['train', 'test', 'validation'] '''
    is3RScan = True
    scan2type = {}
    with open(define.Scan3RJson_PATH, "r") as read_file:
        data = json.load(read_file)
        for scene in data:
            scan2type[scene["reference"]] = scene["type"]
            for scan in scene["scans"]:
                scan2type[scan["reference"]] = scene["type"]
        
    ''' load target scans'''
    target_scan=[]
    if args.target_scan != '':
        target_scan = codeLib.utils.util.read_txt_to_list(args.target_scan)
        
        
    '''  '''
    valid_scans=list()
    relationships_new = dict()
    counter= 0
    with open(os.path.join(define.FILE_PATH + args.relation + ".json"), "r") as read_file:
        data2 = json.load(read_file)
        
    data = list()
    for s in data2["scans"]:
        scan_id = s["scan"]
        if len(target_scan) ==0:
            if scan2type[scan_id] != args.type: 
                continue
        else:
            if scan_id not in target_scan: continue
        data.append(s)
        
        
    '''create h5 file'''
    create_folder(os.path.join(cfg.data.img_feature_path))
    pth_out = os.path.join(cfg.data.img_feature_path,'image_features.h5')
    h5f = h5py.File(pth_out, 'a')
        
    for s in tqdm(data):
        scan_id = s["scan"]
        
        if len(target_scan) ==0:
            if scan2type[scan_id] != args.type: 
                if args.verbose:
                    print('skip',scan_id,'not validation type')
                continue
        else:
            if scan_id not in target_scan: continue
        
        # check if group exist in the h5f
        if scan_id in h5f:
            if args.overwrite==0 and cfg.model.node_encoder.backend in h5f[scan_id]:
                continue
            h5g = h5f[scan_id]
        else:
            h5g = h5f.create_group(scan_id)
        
        gt_relationships = s["relationships"]
        if debug:print('processing scene',scan_id)
        valid_scans.append(scan_id)
        process(
            args.scan_name,
            cfg,
            scan_id, 
            rotate = is3RScan,
            h5g = h5g
            )
        if debug:
            break
    h5f.close()