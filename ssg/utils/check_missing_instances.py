#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar  2 10:24:20 2022

@author: sc

This scripts checks the percetange of missing instaces from the genrated data 
compare tot he full ground truth data.
"""
import os,json,trimesh, argparse
import open3d as o3d
import numpy as np
from pathlib import Path
from tqdm import tqdm
from ssg.utils import util_ply, util_label, util, util_3rscan, util_data
from ssg import define
from codeLib.utils.util import set_random_seed, read_txt_to_list
from ssg.utils.util_data import raw_to_data, cvt_all_to_dict_from_h5
# from utils import util_ply, util_label, util, define
# from utils.util_search import SAMPLE_METHODS,find_neighbors
import h5py,ast
import copy
import logging

def Parser(add_help=True):
    parser = argparse.ArgumentParser(description='Check percentage of valid instances and relationships.', formatter_class = argparse.ArgumentDefaultsHelpFormatter,
                                     add_help=add_help)
    parser.add_argument('--folder','-f', type=str, help="The directory contains generated relationships data.",required=True)
    parser.add_argument('--folder_gt','-g', type=str, help="The directory contains generated relationships data.",required=True)
    # parser.add_argument('--output','-o', type=str,'missing_')
    # parser.add_argument('--type', type=str, default='train', choices=['train', 'test', 'validation'], help="allow multiple rel pred outputs per pair",required=False)
    # parser.add_argument('--label_type', type=str,default='ScanNet20', 
    #                     choices=['3RScan', '3RScan160', 'NYU40', 'Eigen13', 'RIO27', 'RIO7','ScanNet20'], help='label',required=False)
    # # parser.add_argument('--pth_out', type=str,default='../data/tmp', help='pth to output directory',required=True)
    # parser.add_argument('--relation', type=str,default='relationships', choices=['relationships_extended', 'relationships'])
    # parser.add_argument('--target_scan', type=str, default='', help='path to a txt file that contains a list of scan ids that you want to use.')
    # parser.add_argument('--scan_name', type=str, default='graph_2dssg_orbslam3.json', 
    #                     help='what is the name of the output filename of the ply generated by your segmentation method.')
    
    # # options
    # parser.add_argument('--debug', type=int, default=0, help='debug',required=False)
    # # parser.add_argument('--mapping',type=int,default=1,
    # #                     help='map label from 3RScan to label_type. otherwise filter out labels outside label_type.')
    # # parser.add_argument('--v2', type=int,default=1,
    # #                     help='v2 version')
    # # parser.add_argument('--inherit', type=int,default=1,help='inherit relationships from the 3RScan.')
    # parser.add_argument('--verbose', type=bool, default=False, help='verbal',required=False)
    # # parser.add_argument('--scale', type=float,default=1,help='scaling input point cloud.')
    # parser.add_argument('--bbox_min_size', type=int, default=100, 
    #                     help='what is the name of the output filename of the ply generated by your segmentation method.')
    # parser.add_argument('--min_entity_num', type=int, default=2, 
    #                     help='A scene must hhave at least this number of entities.')
    
    # # neighbor search parameters
    # # parser.add_argument('--search_method', type=str, choices=['BBOX','KNN'],default='BBOX',help='How to split the scene.')
    # # parser.add_argument('--radius_receptive', type=float,default=0.5,help='The receptive field of each seed.')
    
    # # split parameters
    # # parser.add_argument('--split', type=int,default=0,help='Split scene into groups.')
    # # parser.add_argument('--radius_seed', type=float,default=1,help='The minimum distance between two seeds.')
    # # parser.add_argument('--min_segs', type=int,default=5,help='Minimum segments for each segGroup')
    # # parser.add_argument('--split_method', type=str, choices=['BBOX','KNN'],default='BBOX',help='How to split the scene.')
    
    # # Correspondence Parameters
    # # parser.add_argument('--max_dist', type=float,default=0.1,help='maximum distance to find corresopndence.')
    # parser.add_argument('--min_3D_bbox_size', type=int,default=0.2*0.2*0.2,help='minimum bounding box region (m^3).')
    # # parser.add_argument('--corr_thres', type=float,default=0.5,help='How the percentage of the points to the same target segment must exceeds this value.')
    # parser.add_argument('--occ_thres', type=float,default=0.5,help='the fraction of GT labels in a segment should exceed this')
    return parser

# def Container(object):
#     def __init__(scan_id,missing_obj,missing_rel):

def replace_to_iid(objs,rels):
    return [(objs[int(src)]['instance_id'],objs[int(tgt)]['instance_id']) for [src,tgt,c,label] in rels if int(src) in objs and int(tgt) in objs]
        
def check(mode:str):
    # ''' load instance mapping'''
    # _, label_name_mapping, _ = util_label.getLabelMapping(args.label_type)
    # segseg_file_name = 'semseg.v2.json' if args.v2 else 'semseg.json'
    # pth_semseg_file = os.path.join(define.DATA_PATH, scan_id, segseg_file_name)
    # instance2labelName = util_3rscan.load_semseg(pth_semseg_file, label_name_mapping,args.mapping)
    
    path_h5 = os.path.join(args.folder,'relationships_%s.h5' % (mode))
    sg_data = h5py.File(path_h5,'r')
    
    path_h5_gt = os.path.join(args.folder_gt,'relationships_%s.h5' % (mode))
    sg_data_gt = h5py.File(path_h5_gt,'r')
    
    '''checking missing scans'''
    scan_ids = set(sg_data.keys())
    scan_ids_gt = set(sg_data_gt.keys())
    missing_scan_ids = scan_ids_gt.difference(scan_ids)
    inter_scan_ids = scan_ids.intersection(scan_ids_gt)
    
    '''check percentage of missing instances and relatinoships'''
    statistics = dict()
    for scan_id in inter_scan_ids:
        scan_data = sg_data[scan_id]
        scan_data_gt = sg_data_gt[scan_id]
        
        scan_data = raw_to_data(scan_data)
        scan_data_gt= raw_to_data(scan_data_gt)
        
        nodes = scan_data['nodes']
        relationships = scan_data['relationships']
        
        nodes_gt = scan_data_gt['nodes']
        relationships_gt = scan_data_gt['relationships']
        
        '''check nodes'''
        instance_ids    = set( [node['instance_id'] for nid,node in nodes.items()] )
        instance_ids_gt = set( [node['instance_id'] for nid,node in nodes_gt.items()] )
        
        missing_node_ids = instance_ids_gt.difference(instance_ids)
        # print('num. of missing_node_ids:',len(missing_node_ids),'(',len(missing_node_ids)/len(instance_ids_gt),')')
        
        '''check relationships'''
        edge_ids = set( replace_to_iid(nodes, relationships) )
        edge_ids_gt = set( replace_to_iid(nodes_gt, relationships_gt) )
        missing_edge_ids = edge_ids_gt.difference(edge_ids)
        
        statistics[scan_id] = (len(missing_node_ids),len(instance_ids_gt), len(missing_edge_ids),len(edge_ids_gt))
        pass
        # break
    # print('number of missing scans:',len(missing_scan_ids))
    return (len(missing_scan_ids),len(scan_ids_gt)), statistics
if __name__ =='__main__':
    args = Parser().parse_args()
    '''read args'''
    with open(os.path.join(args.folder,'args.json')) as f:
        t_args = json.load(f)
    label_type= t_args['label_type']
    relation = t_args['relation']
    mapping = t_args['mapping']
    inherit = t_args['inherit']
    
    
    '''check'''
    # train
    mode = 'test'
    c_scan_ids, statistics = check(mode)
    
    with open('missing_{}.txt'.format(mode),'w') as f:
        f.write('missing scans, total_scans: {} {}\n'.format(c_scan_ids[0],c_scan_ids[1]))
        f.write('scan_id missing_nodes full_nodes missing_edges full_edges missing_node_p missing_edge_p\n')
        for scan_id, data in statistics.items():
            f.write('{} {} {} {} {} {} {}\n'.format(scan_id, data[0],data[1],data[2],data[3], data[0]/data[1],data[2]/data[3]))
    
    

