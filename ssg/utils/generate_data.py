import os,json,trimesh, argparse
# import open3d as o3d
import numpy as np
from pathlib import Path
from tqdm import tqdm
import codeLib
from ssg2d.utils import util_ply, util_label, util, util_3rscan, util_data
import ssg2d.define as define
# from ssg2d.utils.util_search import SAMPLE_METHODS,find_neighbors
from PIL import Image
def Parser(add_help=True):
    parser = argparse.ArgumentParser(description='Process some integers.', formatter_class = argparse.ArgumentDefaultsHelpFormatter,
                                      add_help=add_help)
    parser.add_argument('--type', type=str, default='train', choices=['train', 'test', 'validation'], help="allow multiple rel pred outputs per pair",required=False)
    parser.add_argument('--label_type', type=str,default='ScanNet20', 
                        choices=['3RScan', '3RScan160', 'NYU40', 'Eigen13', 'RIO27', 'RIO7','ScanNet20'], help='label',required=False)
    parser.add_argument('--pth_out', type=str,default='../data/tmp', help='pth to output directory',required=True)
    parser.add_argument('--relation', type=str,default='relationships', choices=['relationships_extended', 'relationships'])
    parser.add_argument('--target_scan', type=str, default='', help='path to a txt file that contains a list of scan ids that you want to use.')    
    parser.add_argument('--target_relationship', type=str, default='', help='target relationship.')    
    parser.add_argument('--scan_name', type=str, default='graph.json', 
                        help='what is the name of the output filename of the ply generated by your segmentation method.')
    parser.add_argument('--bbox_min_size', type=int, default=150, 
                        help='what is the name of the output filename of the ply generated by your segmentation method.')
    
    # options
    parser.add_argument('--mapping',type=int,default=1, help='map label from 3RScan to label_type. otherwise filter out labels outside label_type.')
    parser.add_argument('--v2', type=int,default=1, help='v2 version')
    parser.add_argument('--verbose', type=bool, default=False, help='verbal',required=False)
    parser.add_argument('--debug', type=int, default=0, help='debug',required=False)
    
    # Correspondence Parameters
    parser.add_argument('--min_seg_size', type=int,default=0.2*0.2*0.2,help='minimum bounding box region (m^3).')
    return parser

debug = True
debug = False

def process(
        args,
        label_name_mapping,
        relationships_names,
        scan_id,label_type,
        target_relationships:list,
        gt_relationships:dict=None, verbose=False) -> list:
    ''' load instance mapping'''
    segseg_file_name = 'semseg.v2.json' if args.v2 else 'semseg.json'
    pth_semseg_file = os.path.join(define.DATA_PATH, scan_id, segseg_file_name)
    instance2labelName = util_3rscan.load_semseg(pth_semseg_file, label_name_mapping,args.mapping)
    
    ''' load graph file '''
    pth_pd = os.path.join(define.DATA_PATH,scan_id,args.scan_name)
    graph = util_data.load_graph(pth_pd,box_filter_size=[int(args.bbox_min_size)])
    nodes = graph['nodes']
    keyframes = graph['kfs']
    
    ''' get number of nodes '''
    segment_ids = [k for k in nodes.keys()]
    if 0 in segment_ids: segment_ids.remove(0)
    if args.verbose: print('filtering input segments.. (ori num of segments:',len(segment_ids),')')
    segments_pd_filtered=list()
    for seg_id in segment_ids:
        node = nodes[seg_id]
        if node.kfs is None or len(node.kfs) == 0:
            print('warning. each node should have at least 1 kf')
        
        if node.size() <= args.min_seg_size :
            name = instance2labelName.get(seg_id,'unknown')
            if debug: print('node',seg_id,'(',name,')','too small (', node.size(),'<',args.min_seg_size,')')
            continue

        segments_pd_filtered.append(seg_id)
    segment_ids = segments_pd_filtered
    if debug: print('there are',len(segment_ids), 'segemnts:\n', segment_ids)
    
    ''' check if all instance exist in the semseg file '''
    # for s in segment_ids:
    #     if s not in instance2labelName:
    #         print('missing', s)
    
    ''' filter mapping '''
    instance2labelName_filtered = dict()
    for segment_id in segment_ids:
        if segment_id not in instance2labelName: continue
        if instance2labelName[segment_id] == 'none':continue
        instance2labelName_filtered[segment_id] = instance2labelName[segment_id]
    instance2labelName = instance2labelName_filtered
    
    ''' Save as ply '''
    if debug:    
        ''' load GT '''
        if args.v2:
            pth_gt = os.path.join(define.DATA_PATH,scan_id,'labels.instances.align.annotated.v2.ply')
        else:
            pth_gt = os.path.join(define.DATA_PATH,scan_id,'labels.instances.align.annotated.ply')
        cloud_gt = trimesh.load(pth_gt, process=False)
        # points_gt = np.array(cloud_gt.vertices.tolist()).transpose()
        segments_gt = util_ply.get_label(cloud_gt, '3RScan', 'Segment').flatten()
        
        if args.label_type == 'NYU40':
            colors = util_label.get_NYU40_color_palette()
            cloud_gt.visual.vertex_colors = [0,0,0,255]
            for seg, label_name in instance2labelName.items():
                if label_name == 'none':continue
                segment_indices = np.where(segments_gt == seg)[0]
                label = util_label.NYU40_Label_Names.index(label_name)+1
                for index in segment_indices:
                    cloud_gt.visual.vertex_colors[index][:3] = colors[label]
            cloud_gt.export('tmp_gtcloud.ply')
        else:
            gt_segment_ids = np.unique(segments_gt)
            for gt_seg_id in gt_segment_ids:
                if gt_seg_id not in instance2labelName:
                    segment_indices = np.where(segments_gt == gt_seg_id)[0]
                    for index in segment_indices:
                        cloud_gt.visual.vertex_colors[index][:3] = [0,0,0]
            # for seg, label_name in instance2labelName.items():
            #     segment_indices = np.where(segments_gt == seg)[0]
            #     if label_name != 'none':
            #         continue
            #     for index in segment_indices:
            #         cloud_gt.visual.vertex_colors[index][:3] = [0,0,0]
            cloud_gt.export('tmp_gtcloud.ply')
            
    '''normalize bounding box'''
    for kf in keyframes:
        img_path = kf['path']
        image = Image.open(img_path) # (width, height)
        width,height = image.size[0], image.size[1]
        
        bboxes = kf['bboxes']
        scaled_bboxes=dict()
        for k,box in bboxes.items():
            scaled_box = [box[0]/width, box[1]/height, box[2]/width, box[3]/height] # scale here. since image may be rescaled during data processing
            scaled_bboxes[k] = scaled_box
        kf['bboxes'] = scaled_bboxes

    '''' Save as relationship_*.json '''
    # list_relationships = list()
    relationships = gen_relationship(scan_id,
                                     instance2labelName,
                                     relationships_names,
                                     target_relationships,
                                     gt_relationships)
    # if len(relationships["objects"]) != 0 and len(relationships['relationships']) != 0:
    #         list_relationships.append(relationships)
            
    ''' use filtered objects to generate neighbor dict '''
    tmp_objs = dict()
    for k,v in relationships["objects"].items():
        # segs_neighbors[str(k)] = nodes[k].neighbors.tolist()
        # keyframes[str(k)] = nodes[k].kfs
        tmp_objs[k] = dict()
        tmp_objs[k] = nodes[k].__dict__
        tmp_objs[k]['label'] = v
        # tmp_objs[k]['neighbors'] = nodes[k].neighbors.tolist()
        # tmp_objs[k]['keyframes'] = nodes[k].kfs
    relationships["objects"] = tmp_objs
    relationships['kfs'] = keyframes
    return relationships


def gen_relationship(scan_id:str, 
                     instance2labelName:dict,
                     relationships_names:list,
                     target_relationships:list,
                     gt_relationships:dict=None,
                     target_segments:list=None) -> dict:
    '''' Save as relationship_*.json '''
    relationships = dict() #relationships_new["scans"].append(s)
    relationships["scan"] = scan_id
    
    objects = dict()
    for seg, name in instance2labelName.items():
        if target_segments is not None:
            if seg not in target_segments: continue
        assert(name != '-' and name != 'none')
        objects[int(seg)] = name
    relationships["objects"] = objects
    
    
    split_relationships = list()
    ''' Inherit relationships from ground truth segments '''
    if gt_relationships is not None:
        for rel in gt_relationships:
            id_src = rel[0]
            id_tar = rel[1]
            num = rel[2]
            name = rel[3]
            
            '''check if the idx is correct'''
            idx_in_txt = relationships_names.index(name) # use the ordering from the text file.
            assert(num==idx_in_txt)
            idx_in_txt_new = idx_in_txt
            
            if target_relationships is not None: 
                if name not in target_relationships: continue
                idx_in_txt_new = target_relationships.index(name)
            
            if id_src in instance2labelName and id_tar in instance2labelName:
                if target_segments is not None:
                    if id_src not in target_segments or id_tar not in target_segments: continue
                
                if id_src  not in objects:
                    if debug:print('filter',name,'segment_src', id_src,' is not in objects')
                    continue
                if id_tar  not in objects:
                    if debug:print('filter',name,'segment_src', id_tar,' is not in objects')
                    continue
                
                split_relationships.append([ int(id_src), int(id_tar), idx_in_txt_new, name ])
                if debug:print('inherit', instance2labelName[id_src],name, instance2labelName[id_tar])
            else:
                if debug:
                    if id_src in instance2labelName:
                        print('filter', id_tar,name, 'is not in the instance2labelName')
                    if id_tar in instance2labelName:
                        print('filter', id_src,name, 'is not in the instance2labelName')
    relationships["relationships"] = split_relationships
    return relationships
    
if __name__ == '__main__':
    args = Parser().parse_args()
    debug |= args.debug
    args.verbose |= args.debug
    codeLib.utils.util.set_random_seed(2020)
    
    ''' load semseg file'''
    label_names, label_name_mapping, _ = util_label.getLabelMapping(args.label_type)
    
    '''read classes'''
    classes_json = list()
    for key,value in label_names.items():
        if value == '-':continue
        classes_json.append(value)
    '''read relationships'''
    relationships_names = codeLib.utils.util.read_txt_to_list(os.path.join(define.FILE_PATH, args.relation + ".txt"))
        
    ''' Read Scan and their type=['train', 'test', 'validation'] '''
    scan2type = {}
    with open(define.Scan3RJson_PATH, "r") as read_file:
        data = json.load(read_file)
    for scene in data:
        scan2type[scene["reference"]] = scene["type"]
        for scan in scene["scans"]:
            scan2type[scan["reference"]] = scene["type"]
        
    ''' load target relationship and scans'''
    target_relationships=None
    if args.target_relationship != '':
        target_relationships = codeLib.utils.util.read_txt_to_list(args.target_relationship)
    target_scan=[]
    if args.target_scan != '':
        target_scan = codeLib.utils.util.read_txt_to_list(args.target_scan)
        
        
    '''  '''
    valid_scans=list()
    relationships_new = dict()
    counter= 0
    with open(os.path.join(define.FILE_PATH + args.relation + ".json"), "r") as read_file:
        data2 = json.load(read_file)
        
    data = list()
    for s in data2["scans"]:
        scan_id = s["scan"]
        if len(target_scan) ==0:
            if scan2type[scan_id] != args.type: 
                continue
        else:
            if scan_id not in target_scan: continue
        data.append(s)
        
    for s in tqdm(data):
        scan_id = s["scan"]
        
        # if scan_id != '8eabc447-5af7-2f32-8712-301083e291b3':continue
        
        if len(target_scan) ==0:
            if scan2type[scan_id] != args.type: 
                if args.verbose:
                    print('skip',scan_id,'not validation type')
                continue
        else:
            if scan_id not in target_scan: continue
        
        gt_relationships = s["relationships"]
        
        if debug:print('processing scene',scan_id)
        # print('processing scene',scan_id)
        
        valid_scans.append(scan_id)
        result = process(
            args,
            label_name_mapping,
            relationships_names,
            scan_id, 
            args.label_type, 
            target_relationships,
            gt_relationships = gt_relationships,
            verbose = args.verbose)
        if len(result["objects"]) == 0 or len(result['relationships']) == 0:
            if debug:
                print('skip',scan_id,'len(result["objects"]):',len(result["objects"]),'len(result[\'relationships\'])',len(result['relationships']))
                break
            continue
        
        relationships_new[scan_id] = result
        # relationships_new['neighbors'][scan_id] = segs_neighbors
        # relationships_new['keyframes'][scan_id] = keyframes
        
        if debug:
            break
            
    Path(args.pth_out).mkdir(parents=True, exist_ok=True)
    pth_args = os.path.join(args.pth_out,'args.json')
    with open(pth_args, 'w') as f:
            tmp = vars(args)
            json.dump(tmp, f, indent=2)
    
    pth_relationships_json = os.path.join(args.pth_out, "relationships_" + args.type + ".json")
    with open(pth_relationships_json, 'w') as f:
        json.dump(relationships_new, f)
    pth_classes = os.path.join(args.pth_out, 'classes.txt')
    with open(pth_classes,'w') as f:
        for name in classes_json:
            if name == '-': continue
            f.write('{}\n'.format(name))
    pth_relation = os.path.join(args.pth_out, 'relationships.txt')
    with open(pth_relation,'w') as f:
        if target_relationships is None:
            target_relationships = relationships_names
        for name in target_relationships:
            f.write('{}\n'.format(name))
                
    pth_split = os.path.join(args.pth_out, args.type+'_scans.txt')
    with open(pth_split,'w') as f:
        for name in valid_scans:
            f.write('{}\n'.format(name))